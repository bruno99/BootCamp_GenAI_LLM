{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# QA over PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* We will create a Q&A app that can answer questions about PDF files.\n",
    "* We will use a Document Loader to load text in a format usable by an LLM, then build a retrieval-augmented generation (RAG) pipeline to answer questions, including citations from the source material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### Recommended: create new virtualenv\n",
    "* mkdir your_project_name\n",
    "* cd your_project_name\n",
    "* pyenv virtualenv 3.11.4 your_venv_name\n",
    "* pyenv activate your_venv_name\n",
    "* pip install jupyterlab\n",
    "* jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f9e964-c5c2-4a13-b9ed-c449362ae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "#### .env File\n",
    "Remember to include:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **qaFromPDF**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99edb898-4503-429d-ad7d-fad4fc74300f",
   "metadata": {},
   "source": [
    "## Load the PDF file\n",
    "* The loader reads the PDF at the specified path into memory.\n",
    "* It then extracts text data using the pypdf package.\n",
    "* Finally, it creates a LangChain Document for each page of the PDF with the page's content and some metadata about where in the document the text came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903027c-722c-4b9f-8717-b3affb844227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a191a2-133a-4bae-be2c-0b9f226c0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "764957d8-b4b3-4555-affc-187203e85293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./data/Be_Good.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb64f5c-d5da-4c60-9418-a9d5407faa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be Good - Essay by Paul Graham\n",
      "Be Good\n",
      "Be good\n",
      "April 2008(This essay is derived from a talk at the 2\n",
      "{'source': './data/Be_Good.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:100])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1148577-8c06-47fb-9d48-fa9ce7f14e30",
   "metadata": {},
   "source": [
    "## RAG\n",
    "* We will use the vector database (aka. vector store) Chroma DB.\n",
    "* Using a text splitter, we will split the loaded PDF into smaller documents that can more easily fit into an LLM's context window, then load them into a vector store.\n",
    "* We can then create a retriever from the vector store for use in our RAG chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21711cdc-510e-4738-b8ba-28135b4b7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ae6680-d314-435f-9213-ffb66bac7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f674aa-167a-46f1-8e5c-c7f62d237092",
   "metadata": {},
   "source": [
    "* We will then use some built-in helpers to construct the final rag_chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac58036b-b6bc-44d6-8d76-b6141d8a9da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The essay \"Be Good\" by Paul Graham discusses the importance of creating something that people want and not worrying about making money initially when starting a business. Graham explores the idea of businesses being similar to charities and the advantages of focusing on user satisfaction. The essay also mentions examples like Google and Craigslist to illustrate these concepts.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": \"What is this article about?\"})\n",
    "\n",
    "results[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89746b08-1ae3-4f9b-971d-449a32d9c7e7",
   "metadata": {},
   "source": [
    "* If you print the whole `results` you will see that you get both a final answer in the answer key of the results dict, and the context the LLM used to generate an answer. See it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e341ec-36f7-4703-97d5-ce71cd2ecac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is this article about?',\n",
       " 'context': [Document(page_content=\"Be Good - Essay by Paul Graham\\nBe Good\\nBe good\\nApril 2008(This essay is derived from a talk at the 2008 Startup School.)About a month after we\\nstarted Y Combinator we came up with the\\nphrase that became our motto: Make something people want.  We've\\nlearned a lot since then, but if I were choosing now that's still\\nthe one I'd pick.Another thing we tell founders is not to worry too much about the\\nbusiness model, at least at first.  Not because making money is\\nunimportant, but because it's so much easier than building something\\ngreat.A couple weeks ago I realized that if you put those two ideas\\ntogether, you get something surprising.  Make something people want.\\nDon't worry too much about making money.  What you've got is a\\ndescription of a charity.When you get an unexpected result like this, it could either be a\\nbug or a new discovery.  Either businesses aren't supposed to be\\nlike charities, and we've proven by reductio ad absurdum that one\", metadata={'page': 0, 'source': './data/Be_Good.pdf'}),\n",
       "  Document(page_content=\"Be Good - Essay by Paul Graham\\nGoogle does.Most explicitly benevolent projects don't hold themselves sufficiently\\naccountable.  They act as if having good intentions were enough to\\nguarantee good effects.[3] Users dislike their\\nnew operating system so much that they're starting petitions to\\nsave the old one.  And the old one was nothing special.  The hackers\\nwithin Microsoft must know in their hearts that if the company\\nreally cared about users they'd just advise them to switch to OSX.Thanks to Trevor Blackwell, Paul\\nBuchheit, Jessica Livingston,\\nand Robert Morris for reading drafts of this.\\nPage 11\", metadata={'page': 10, 'source': './data/Be_Good.pdf'}),\n",
       "  Document(page_content=\"Be Good - Essay by Paul Graham\\ncaptains always try to get upwind\\nof their opponents.  If you're upwind, you decide when and if to\\nengage the other ship.  Craigslist is effectively upwind of enormous\\nrevenues.  They'd face some challenges if they wanted to make more,\\nbut not the sort you face when you're tacking upwind, trying to\\nforce a crappy product on ambivalent users by spending ten times\\nas much on sales as on development.  [1]I'm not saying startups should aim to end up like\\nCraigslist.\\nThey're a product of unusual circumstances.  But they're a good\\nmodel for the early phases.Google looked a lot like a charity in the beginning. They didn't\\nhave ads for over a year.  At year 1, Google was indistinguishable\\nfrom a nonprofit.  If a nonprofit or government organization had\\nstarted a project to index the web, Google at year 1 is the limit\\nof what they'd have produced.Back when I was working on spam filters I thought it would be a\", metadata={'page': 1, 'source': './data/Be_Good.pdf'}),\n",
       "  Document(page_content=\"Be Good - Essay by Paul Graham\\nyou've basically built yourself a giant tamagotchi.  You've made\\nsomething you need to take care of.Blogger is a famous example of a startup that went through\\nreally\\nlow lows and survived.  At one point they ran out of money and\\neveryone left. Evan Williams came in to work the next day, and there\\nwas no one but him.  What kept him going?  Partly that users needed\\nhim.  He was hosting thousands of people's blogs. He couldn't just\\nlet the site die.There are many advantages of launching quickly, but the most important\\nmay be that once you have users, the tamagotchi effect kicks in.\\nOnce you have users to take care of, you're forced to figure out\\nwhat will make them happy, and that's actually very valuable\\ninformation.The added confidence that comes from trying to help people can\\nalso help you with investors. One of the founders of \\nChatterous told \\nme recently that he and his cofounder had decided that this service\", metadata={'page': 5, 'source': './data/Be_Good.pdf'})],\n",
       " 'answer': 'The essay \"Be Good\" by Paul Graham discusses the importance of creating something that people want and not worrying about making money initially when starting a business. Graham explores the idea of businesses being similar to charities and the advantages of focusing on user satisfaction. The essay also mentions examples like Google and Craigslist to illustrate these concepts.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7225ee-ff03-4c41-a4b5-1138ab3cfbfb",
   "metadata": {},
   "source": [
    "* Examining the values under the context further, you can see that they are documents that each contain a chunk of the ingested page content. These documents also preserve the original metadata from way back when you first loaded them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2153a091-c9cb-489e-b505-c9691b4cc774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': './data/Be_Good.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(results[\"context\"][0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a05cb-2700-4f40-9b39-5313f636391e",
   "metadata": {},
   "source": [
    "* This particular chunk came from page 0 in the original PDF. You can use this data to show which page in the PDF the answer came from, allowing users to quickly verify that answers are based on the source material."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
