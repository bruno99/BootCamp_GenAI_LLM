{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# How to build an advanced Chatbot with session memory using LangChain\n",
    "* Advanced Chatbot LLM App.\n",
    "    * Will be able to have a conversation.\n",
    "    * Will remember previous interactions: will have memory.\n",
    "    * Will be able to have different memories for different user sessions.\n",
    "    * Will be able to remember a limited number of messages: limited memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0399355-dece-4701-9bf4-4c204fe74929",
   "metadata": {},
   "source": [
    "## Concepts included\n",
    "* Chat Model vs. LLM Model:\n",
    "    *  Chat Model is based around messages.\n",
    "    *  LLM Model is based around raw text.\n",
    "* Chat History: allows Chat Model to remember previous interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48386f20-c929-48a9-8720-0953fcd67dd0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ee060-21f2-4e01-b283-1fd656dac1e9",
   "metadata": {},
   "source": [
    "#### Recommended: create new virtualenv\n",
    "* mkdir your_project_name\n",
    "* cd your_project_name\n",
    "* pyenv virtualenv 3.11.4 your_venv_name\n",
    "* pyenv activate your_venv_name\n",
    "* pip install jupyterlab\n",
    "* jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f11855b-e12a-4756-8893-7d00244c8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2ba54-ace7-4719-b6c2-7713a615614d",
   "metadata": {},
   "source": [
    "#### .env File\n",
    "Remember to include:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a63ff6-99ff-4629-b965-547d12a99ba6",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **advancedChatbot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03febb1-c3de-485a-ae2d-b68066790912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                 0.2.1\n",
      "langchain-community       0.2.1\n",
      "langchain-core            0.2.2\n",
      "langchain-openai          0.1.8\n",
      "langchain-text-splitters  0.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenAI's gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatbot = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1d409-7f2f-40a4-90c5-ad77dad3edce",
   "metadata": {},
   "source": [
    "* Human Message: the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5dc0613-fb6d-4c82-a614-9e7307714303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messagesToTheChatbot = [\n",
    "    HumanMessage(content=\"My favourite color is blue.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b36ec-341a-47bc-af32-30cfb939810d",
   "metadata": {},
   "source": [
    "#### Call the ChatModel (the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db815e32-8e60-46b3-8cce-fbf40e378397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Blue is such a calming and peaceful color. It's often associated with stability and trustworthiness. What do you like most about the color blue?\", response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 13, 'total_tokens': 43}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-484b5288-6948-495f-88a1-cdd01e48f626-0', usage_metadata={'input_tokens': 13, 'output_tokens': 30, 'total_tokens': 43})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messagesToTheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913fc8c-254f-410d-aa8f-35eb0898855e",
   "metadata": {},
   "source": [
    "#### Track the operation in LangSmith\n",
    "* [Open LangSmith here](smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62b67b-9798-4705-8b8a-dbfdf8c93ed8",
   "metadata": {},
   "source": [
    "## Check if the Chatbot remembers your favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ead4ee-bda3-4c52-9bdb-7bf234733055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I'm not able to know your favorite color as an AI assistant. Can you please tell me what your favorite color is?\", response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 13, 'total_tokens': 42}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-75666902-eef4-4507-ba38-75b0b7e8a886-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"What is my favorite color?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec947e-b9b7-43e3-ac67-60027e049f3c",
   "metadata": {},
   "source": [
    "* As you can see, our Chatbot cannot remember our previous interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0143e-8bc8-45ad-ac6f-05aaf659c683",
   "metadata": {},
   "source": [
    "## Let's add memory to our Chatbot\n",
    "* We will use the ChatMessageHistory package.\n",
    "* We will save the Chatbot memory in a python dictionary called chatbotMemory.\n",
    "* We will define the get_session_history function to create a session_id for each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23533a37-6060-4d32-9b0c-36a9ea57a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c1d395-0656-46f4-a14e-70cd3e30e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "chatbotMemory = {}\n",
    "\n",
    "# input: session_id, output: chatbotMemory[session_id]\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chatbotMemory:\n",
    "        chatbotMemory[session_id] = ChatMessageHistory()\n",
    "    return chatbotMemory[session_id]\n",
    "\n",
    "\n",
    "chatbot_with_message_history = RunnableWithMessageHistory(\n",
    "    chatbot, \n",
    "    get_session_history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c9c5e",
   "metadata": {},
   "source": [
    "This previous code manages the chatbot's memory of conversations based on session identifiers. Hereâ€™s a breakdown of what the different components do:\n",
    "\n",
    "1. **chatbotMemory**:\n",
    "    - `chatbotMemory = {}`: This initializes an empty dictionary where session IDs and their respective chat histories will be stored.\n",
    "\n",
    "2. **get_session_history Function**:\n",
    "    - This function, `get_session_history`, takes a `session_id` as an argument and returns the chat history associated with that session.\n",
    "    - If a chat history for the given `session_id` does not exist in `chatbotMemory`, a new instance of `ChatMessageHistory` is created and assigned to that `session_id` in the dictionary.\n",
    "    - The function ensures that each session has its own unique chat history, stored and retrieved using the session ID.\n",
    "\n",
    "3. **chatbot_with_message_history**:\n",
    "    - `chatbot_with_message_history = RunnableWithMessageHistory(chatbot, get_session_history)`: This line creates an instance of `RunnableWithMessageHistory` using two arguments: `chatbot` and `get_session_history`.\n",
    "    - The `chatbot` is passed along with the `get_session_history` function. This setup integrates the chatbot with the functionality to handle session-specific chat histories, allowing the chatbot to maintain continuity and context in conversations across different sessions.\n",
    "\n",
    "Overall, the code organizes and manages a chatbot's memory, enabling it to handle different sessions with users effectively by remembering previous messages within each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d51d451-ed97-4752-88df-de8072e45f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "session1 = {\"configurable\": {\"session_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d3961a-b565-45b5-a45f-2332ab03cd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a bold and vibrant choice! Red is often associated with energy, passion, and strength. Do you have a specific reason why red is your favorite color?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My favorite color is red.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "378a4aae-c392-439d-a7ea-4ae91a677075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d37c98-3883-4210-a162-5302e109e743",
   "metadata": {},
   "source": [
    "## Let's now change the session_id and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f82b3e0-7897-4aa8-b554-1985a3af4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = {\"configurable\": {\"session_id\": \"002\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "882d0fc2-4360-4205-8cc7-bc7275295eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have that information. Can you please tell me what your favorite color is?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my favorite color?\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ec598-2b9f-4da1-b169-b270f820df9e",
   "metadata": {},
   "source": [
    "## Let's go back to session_id 001 and see if the memory is still there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36c102a-1f06-490f-88b7-cb6e6380d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "session1 = {\"configurable\": {\"session_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f61f9a-b8d5-4149-97cd-c7b6c8683bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037264c-71aa-47f2-9512-e78c12761eaa",
   "metadata": {},
   "source": [
    "## Our ChatBot has session memory now. Let's check if it remembers the conversation from session 002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac2a638-7968-4475-8cf8-9af8440f3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = {\"configurable\": {\"session_id\": \"002\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d367cb8f-1109-45ca-8e7a-1b76a096ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Julio! It's nice to meet you. If you'd like to share your favorite color with me, I'd be happy to remember it for future reference.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Mi name is Julio.\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39ac2ecd-9800-467e-a612-9e3264185875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Julio.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c649bdcc-a393-406b-8121-4cd25ae11163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbce7cd-399d-42f3-be81-bff26506cfbc",
   "metadata": {},
   "source": [
    "## Our chatBot now remembers each of our conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39070b3d-5de9-4751-966e-98b17a4db745",
   "metadata": {},
   "source": [
    "## The importance to manage the Conversation History\n",
    "* The memory of a chatbot is included in the context window of the LLM so, if left unmanaged, can potentially overflow it.\n",
    "* We are now going to learn how to limit the size of the memory of a chatbot.\n",
    "* First, let's take a look at what is in the memory of our chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09547883-82fc-480a-8f58-fd7fbc007fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'001': InMemoryChatMessageHistory(messages=['Human: My favorite color is red.', AIMessage(content=\"That's a bold and vibrant choice! Red is often associated with energy, passion, and strength. Do you have a specific reason why red is your favorite color?\", response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 13, 'total_tokens': 46}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e5fde172-58ef-4f73-b463-a2a463d0a1f7-0', usage_metadata={'input_tokens': 13, 'output_tokens': 33, 'total_tokens': 46}), AIMessage(content='Your favorite color is red!', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 62, 'total_tokens': 68}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-99eebba4-d387-4a22-b717-1180116d043a-0', usage_metadata={'input_tokens': 62, 'output_tokens': 6, 'total_tokens': 68}), AIMessage(content='Your favorite color is red!', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 72, 'total_tokens': 78}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-77733a8c-0946-494a-8dd5-adaef779c8cf-0', usage_metadata={'input_tokens': 72, 'output_tokens': 6, 'total_tokens': 78}), AIMessage(content='Your favorite color is red!', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 82, 'total_tokens': 88}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-23843ab4-9019-420b-827b-9d356c769699-0', usage_metadata={'input_tokens': 82, 'output_tokens': 6, 'total_tokens': 88})]), '002': InMemoryChatMessageHistory(messages=[\"Human: What's my favorite color?\", AIMessage(content=\"I'm sorry, I don't have that information. Can you please tell me what your favorite color is?\", response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 13, 'total_tokens': 35}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cf503e96-07c9-456a-8eff-9f4e74b962e3-0', usage_metadata={'input_tokens': 13, 'output_tokens': 22, 'total_tokens': 35}), AIMessage(content=\"Hello Julio! It's nice to meet you. If you'd like to share your favorite color with me, I'd be happy to remember it for future reference.\", response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 50, 'total_tokens': 83}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0e3f7722-ef1a-424d-a968-4f60683a15e5-0', usage_metadata={'input_tokens': 50, 'output_tokens': 33, 'total_tokens': 83}), AIMessage(content='Your name is Julio.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 87, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4181b321-0aeb-4b69-bfb9-5c0f70ad24b5-0', usage_metadata={'input_tokens': 87, 'output_tokens': 5, 'total_tokens': 92})])}\n"
     ]
    }
   ],
   "source": [
    "print(chatbotMemory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a7229-ea29-468b-93e1-b2b52951b47c",
   "metadata": {},
   "source": [
    "* Now, let's define a function to limit the number of messages stored in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd33a1bb-d3c4-4011-99c7-105e3d7051e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def limited_memory_of_messages(messages, number_of_messages_to_keep=2):\n",
    "    return messages[-number_of_messages_to_keep:]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "limitedMemoryChain = (\n",
    "    RunnablePassthrough.assign(messages=lambda x: limited_memory_of_messages(x[\"messages\"]))\n",
    "    | prompt \n",
    "    | chatbot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff26a10-27aa-48ef-a3f0-867d3f819c79",
   "metadata": {},
   "source": [
    "* The limited_memory_of_messages function allows you to trim the list of stored messages, keeping only a specified number of the latest ones. For example, if you have a long list of messages and you only want to keep the last two, this function will do that for you.\n",
    "* The lambda function works in conjunction with the `limited_memory_of_messages` function. Hereâ€™s a simple breakdown:\n",
    "\n",
    "    1. **Lambda Function**: The `lambda` keyword is used to create a small anonymous function in Python. The `lambda` function defined here takes one argument, `x`.\n",
    "\n",
    "    2. **Function Argument**: The argument `x` is expected to be a dictionary that contains a key named `\"messages\"`. The value associated with this key is a list of messages.\n",
    "\n",
    "    3. **Function Body**: The body of the `lambda` function calls the `limited_memory_of_messages` function. It passes the list of messages found in `x[\"messages\"]` to this function.\n",
    "\n",
    "    4. **Default Behavior of limited_memory_of_messages**: Since the `lambda` function does not specify the `number_of_messages_to_keep` parameter when it calls `limited_memory_of_messages`, the latter will default to keeping the last 2 messages from the list (as defined by the earlier function).\n",
    "\n",
    "In essence, the `lambda` function is a shorthand way to apply the `limited_memory_of_messages` function to the message list contained within a dictionary. It automatically trims the list to the last two messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e45d4cd1-2165-451d-939f-66f9cc898c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_with_limited_message_history = RunnableWithMessageHistory(\n",
    "    limitedMemoryChain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39981-02c7-4d10-a4a8-2efbe9bb3c89",
   "metadata": {},
   "source": [
    "#### Let's add 2 more messages to the session1 conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76687e6a-2bbf-450f-8310-7011646fea3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a fun choice! Vespa scooters are known for their classic and stylish design. They are also great for getting around town and exploring new places. What is it about Vespa scooters that you like the most?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My favorite vehicles are Vespa scooters.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c8a9b0c-7ae5-4f3b-b93b-06462c6d3199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'San Francisco is a beautiful city with its iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and cable cars. The diverse culture, amazing food scene, and stunning views of the bay make it a favorite for many people. What do you love most about San Francisco?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My favorite city is San Francisco.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c688e6-3e9f-4c11-a4f7-38eb8dd35666",
   "metadata": {},
   "source": [
    "## The chatbot memory has now 4 messages. Let's check the Chatbot with limited memory. \n",
    "* Remember, this chatbot only remembers the last 2 messages, so if we ask her about the first message she should not remember it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16875068-39fd-419e-84b0-f3363f30a3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI assistant, I don't have access to personal information about you, such as your favorite color. If you'd like to share your favorite color with me, I'd be happy to discuss it further.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_limited_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what is my favorite color?\")],\n",
    "    },\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9989ae1-d75b-4b8f-9235-b4eb110e102d",
   "metadata": {},
   "source": [
    "* The chatbot with limited memory has behaved as we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324091a-dc49-42af-b638-324dc646cdae",
   "metadata": {},
   "source": [
    "## Finally, let's compare the previous response with the one provided by the Chatbot with unlimited memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "251e1915-dabf-4591-82cc-a0fa8b465ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is red!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e34b2-3c42-4ef7-9deb-18c2ec374adc",
   "metadata": {},
   "source": [
    "* As you can see, this chatbot remembers our first message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735752cc-ecb5-4942-9ed0-b3213f5768c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
