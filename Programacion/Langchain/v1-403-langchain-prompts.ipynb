{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f43cd88-3539-41b2-a829-72321a5265c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116ac35-4006-47df-8612-ad33d43e934f",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e69458-e76b-4cf2-a208-c52f6aa64868",
   "metadata": {},
   "source": [
    "A prompt is the input we provide to one language model. This input will guide the way the language model will respond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5b71fb-ab01-4894-89db-11fe728f5900",
   "metadata": {},
   "source": [
    "There are many types of prompts:\n",
    "* Plain instructions.\n",
    "* Instructions with a few examples (few-shot examples).\n",
    "* Specific context and questions appropiate for a given task.\n",
    "* Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d32ac-7a5b-478c-b88d-acb8814b8830",
   "metadata": {},
   "source": [
    "LangChain provides a useful list of prompt recipes [here](https://smith.langchain.com/hub?ref=blog.langchain.dev)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0ceaa-9776-4151-9f1a-4c3ad8ebbef6",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3751480-ec5f-4e72-ae75-eda976691a6f",
   "metadata": {},
   "source": [
    "Prompt templates are pre-defined prompt recipes that usually need some extra pieces to be complete. These extra pieces are variables that the user will provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9758a2-d919-4f72-ac4d-80d00c59a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0db43f-73a6-43bd-9679-710cf8508a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c499d3-5146-4848-b7ba-edea90afe0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00564b6d-53c5-4b6a-8898-25749906a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_template = \"\"\"\n",
    "Tell me a {adjective} joke about {topic}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae54277-4fdb-406e-9a73-3e38f8ddbb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"topic\"],\n",
    "    template=my_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebf7622-1e1a-489b-b118-e32627c6d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = {\n",
    "    \"adjective\": \"funny\",\n",
    "    \"topic\": \"French\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187677a9-f99c-4e8a-8314-934d02322096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funny\n"
     ]
    }
   ],
   "source": [
    "print(user_input[\"adjective\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7583ed-1bb5-4d5a-b674-fc66522dfcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt_template.format(\n",
    "    adjective=user_input[\"adjective\"], \n",
    "    topic=user_input[\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e7098b-5637-4db7-9416-1e052b7855e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliocolomer/.pyenv/versions/3.11.4/envs/venv020124/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why did the French chef only use one egg in his omelette?\n",
      "\n",
      "Because in France, one egg is un Å“uf!\n"
     ]
    }
   ],
   "source": [
    "print(llm(final_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d70962-615b-44ce-a85e-535e1a49bb74",
   "metadata": {},
   "source": [
    "## Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c99304-c21d-4d97-b389-fd1469de76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13dc82dc-e0f3-4feb-9969-ae861f8ba2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68d6e9a2-b473-4411-b53b-e2548b357283",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb46fdff-960c-4468-8a58-1518d76086cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{user_input}\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "222dabb6-f736-481e-8161-477e31291318",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_user_input = \"How many hours have one year?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e3a1de0-556c-4a27-b615-732b05b4a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliocolomer/.pyenv/versions/3.11.4/envs/venv020124/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One year typically has 8,760 hours.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(chat_template.format_messages(user_input=my_user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f846d9-ee3c-46d9-a668-be459d080f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
